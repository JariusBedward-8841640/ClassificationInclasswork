{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-26T22:41:43.201932Z",
     "start_time": "2025-11-26T22:41:43.197225Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Use Cats & Dogs Dataset Load a subset of the data\n",
    "##Create random bounding box in each image\n",
    "## Define a model that is able to do both:\n",
    "## 1. Classify the image either cat or dog\n",
    "## 2. Predict the bounding box that was generated in the begging"
   ],
   "id": "68d344b5d0d62c09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### setup",
   "id": "3f6d2325bc6a6bed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T22:41:57.684724Z",
     "start_time": "2025-11-26T22:41:43.216636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# path to images\n",
    "data_dir = \"data/train/\"\n",
    "\n",
    "img_size = 128\n",
    "\n",
    "images = []# hold image tensors after loading\n",
    "labels = [] # hold corresponding labels for each list\n",
    "\n",
    "for fname in os.listdir(data_dir):\n",
    "    if fname.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(data_dir, fname)\n",
    "        #load and resize image\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (img_size, img_size))\n",
    "        img = tf.cast(img, tf.float32)\n",
    "\n",
    "        images.append(img)\n",
    "\n",
    "        # assing label based on filename\n",
    "        if \"cat\" in fname.lower():\n",
    "            labels.append(0)\n",
    "        elif \"dog\" in fname.lower():\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            continue # skips it if not clear\n",
    "\n",
    "\n",
    "# converts to tensors\n",
    "\n",
    "images = tf.stack(images)\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "eb659111ae5765a3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create a random bounding box in each image",
   "id": "7ad378501b58c6d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T22:42:03.339853Z",
     "start_time": "2025-11-26T22:41:57.734939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#to create t random bounding box you need to pick two random x and y and it starts with minium x and then starts with min y then max x nad max y\n",
    "\n",
    "def preprocess_bound_box(image):\n",
    "    #resizes and normalize the image\n",
    "    image = tf.image.resize(image, (img_size, img_size))\n",
    "    image = tf.cast(image, tf.float32) / 255.0 # divide by 255.0 to normalize pixel values\n",
    "    #pixel values range 0,255 for each color channel\n",
    "    # Nueral network work better with smaller ranges\n",
    "\n",
    "    #Generate random bounding box in nroamlized coordinates\n",
    "    #Ensure   x_min < x_max and y_min < y_max\n",
    "#picks random float in the range\n",
    "    x_min = np.random.uniform(0, 0.5) #0, 0.5 to make sure box starts somewhree top left half\n",
    "    y_min = np.random.uniform(0, 0.5)\n",
    "\n",
    "    x_max = np.random.uniform(0.5, 1.0)\n",
    "    y_max = np.random.uniform(0.5, 1.0)\n",
    "\n",
    "    boundbox = np.array([x_min, y_min, x_max, y_max], dtype=np.float32)\n",
    "\n",
    "    return image, boundbox\n",
    "\n",
    "#ex usage with list of images\n",
    "\n",
    "processed_images = []\n",
    "boundboxes = []\n",
    "\n",
    "for img in images:\n",
    "    img_proc, boundbox = preprocess_bound_box(img)\n",
    "    processed_images.append(img_proc)\n",
    "    boundboxes.append(boundbox)\n",
    "\n",
    "processed_images = tf.stack(processed_images)\n",
    "boundboxes = tf.stack(boundboxes)\n",
    "\n",
    "print(\"Processed images shape\", processed_images.shape)\n",
    "print(\"Boundboxes shape\", boundboxes.shape)\n",
    "print(\"Example Bound box:\", boundboxes[0].numpy())\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "40f4fb15f03322ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images shape (4097, 128, 128, 3)\n",
      "Boundboxes shape (4097, 4)\n",
      "Example Bound box: [0.43754366 0.26004314 0.65264034 0.5635852 ]\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
